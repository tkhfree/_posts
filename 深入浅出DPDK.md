---
title: 深入浅出DPDK
toc: true
thumbnail: 'https://pic.downk.cc/item/5eda03efc2a9a83be5241038.jpg'
comments: true
tags:
  - DPDK
date: 2020-07-23 09:01:21
urlname:
categories:
---

最近在做T4P4s多目标编译器，崔博要求T4P4s的前端编译要与DPDK结合起来实现数据平面的完全可编程，并且数据带宽达到40Gbs。就看一下DPDK这本书，结合白皮书入入门。

在早期的网络收发数据量不是特别大的时候，比如10Mbs、100Mbs的传输速率，数据报文的处理都是经过通用架构的Linux内核态，一个报文到来产生一次中断请求，cpu去处理网络报文，当传输速率提升到万兆，甚至英特尔推出的40Gbs、100Gbs的传输速率标准时，仅靠cpu5Ghz的时钟频率显然是不够看的，因此将网络数据的处理从内核态转到应用态是一个发展方向。再此之前的解决方案有轮询，指的是一次中断批处理一批网络报文，而不是一个报文中断一次；还有内存共享技术，减少处理的数据从内核复制到用户的消耗。

### 数据包处理能力

吞吐、延迟、丢包率、抖动

对于转发，常以包转发率（每秒包转发率pps）而不是bit/s来衡量转发效率

一般所说的接口带宽，1Gbit/s、10Gbit/s、25Gbit/s、40Gbit/s、100Gbit/s，代表以太接口线路上所能承载的最高传输比特率，其单位是 bit/s(bit per second， 位 / 秒)。实际上，不可能每个比特都传输有效数据。以太网每个帧之间会有帧间距(Inter- Packet Gap，IPG)，默认帧间距大小为 12 字节。每个帧还有 7 个字节的前导(Preamble)，和 1 个字节的帧首定界符(Start Frame Delimiter，SFD)。

## Cache和内存

### 系统架构的演进

经典计算机系统中的内存架构：

[![](https://pic.downk.cc/item/5f19765614195aa594489c4e.jpg)](https://pic.downk.cc/item/5f19765614195aa594489c4e.jpg)

所有的数据交换都需要经过北桥

1. 处理器访问内存
2. 处理器访问外设
3. 外设访问处理器
4. 外设访问内存

因此，北桥的性能成了系统性能的瓶颈，因此推出了一种架构：

![](https://pic.downk.cc/item/5f19783614195aa59449ad36.png)

这里增加了内存的访问带宽，缓解了不同设备对同一内存访问的拥塞问题，但是没有改进单一北桥芯片的瓶颈问题。为了解决这个问题，产生了NUMA(non-uniform memory architecture非一致性内存架构)系统

![](https://pic.downk.cc/item/5f1ae97214195aa594168cb0.png)

这样的系统架构不需要一个复杂的北桥就能将内存带宽增加到以前的四倍，但是该系统也有缺点，访问内存所花费的时间与处理器有关，如果处理器访问本地内存时间很短，如果访问远程内存，则需要跨越一个或者两个cpu。因此访问内存的时间也是不确定的。

### Cache系统简介

Cache有三级，以前一级和二级放在处理器内部，三级放在主板上，主要是因为三级cache太大，集成进处理器需要的晶体管数量太多，现在工艺都到个位数纳米了，可以集成更多的晶体管，三级cache也被集成进处理器了。

- 一级cache

  一般分为数据cache和指令cache，数据cache主要用来存储数据，而指令cache用于存放指令。这种cache处理速度最快，一般只需要3-5个指令周期就可以访问到数据，因此成本高，容量小，一般都只有几十kb。在多核处理器内部，每个核心都拥有属于自己的一级cache。

- 二级cache

  数据和指令都无差别的存放在一起。速度比一级cache要慢，处理器大约需要十几个处理周期才能访问到数据，一般几百kb到几mb，在多核处理器内部每个核都拥有自己的二级cache。

- 三级cache

  多核处理器共用一个cache。导致一个问题，有可能一个内核占用了大部分的三级cache，而其他内核用极小一部分cache，从而导致cache不命中，性能下降

#### TLB cache

 当程序员直接访问物理地址进行编程时，当程序出现错误，整个系统都崩掉了；或者一个应用程序调用另一个应用程序的写操作，会让另一个应用程序崩掉。因此提出了虚拟内存和分段分页技术。

软件使用虚拟地址访问内存，而处理器负责虚拟地址到物理地址的映射工作，为了完成映射，处理器采取多级页表来进行多次查找找到真正的物理地址。如果查找不到就会产生缺页异常，不会影响到其他的应用程序。

页表存储在内存中，当需要根据虚拟地址查找物理地址时，就要到内存中寻找页目录表和页存表。如果采用TLB Cache的话，集成到处理器内部，就可以大大缩减访问内存的时间，TLB Cache缓存内存中的页表项，采用相连存储器，直接搜索虚拟地址，返回物理地址。如果TLB不命中，则要去内存中查找。

### Cache地址映射和变换

Cache一般只有20-30MB，内存都是以GB为单位的，怎么把内存放到缓存里面呢。这就需要一个映射算法和分块机制。

- 分块机制：是指Cache和内存都是以块进行数据交换，块的大小通常都是以内存一个存储周期中能够访问的数据长度为限。主流块的大小时64字节Bytes，因此一个Cache line就是64字节大小的字节块。
- 映射算法：是指把内存地址空间和Cache地址空间映射起来，把内存中的内容按照某种规则放到Cache中，当处理器需要某个数据块的内容，则可以根据映射规则去Cache中获取

#### 全关联性Cache

全关联型 Cache 是指主存中的任何一块内存都可以映射到 Cache 中的任意一块位置上。在 Cache 中，需要建立一个目录表，目录表的每个表项都有三部分组成:内存块地址、Cache 块号和一个有效位。当处理器需要访问某个内存地址时，首先通过该目录表查询是否该内容缓存在 Cache 中。

首先，用内存的块地址 A 在 Cache 的目录表中进行查询，如果找到等值的内存块地址， 检查有效位是否有效，只有有效的情况下，才能通过 Cache 块号在 Cache 中找到缓存的内 存，并且加上块内地址 B，找到相应数据，这时则称为 Cache 命中，处理器拿到数据返回; 否则称为不命中，处理器则需要在内存中读取相应的数据。

可以看出，使用全关联型 Cache，块的冲突最小(没有冲突)，Cache 的利用率也高，但是需要一个访问速度很快的相联存储器。随着 Cache 容量的增加，其电路设计变得十分复杂，因此只有容量很小的 Cache 才会设计成全关联型的(如一些英特尔处理器中的 TLB Cache)。

#### 直接关联型Cache

直接关联型 Cache 是指主存中的一块内存只能映射到 Cache 的一个特定的块中。假设 一个 Cache 中总共存在 N 个 Cache line，那么内存被分成 N 等分，其中每一等分对应一个 Cache line。举个简单的例子，假设 Cache 的大小是 2K，而一个 Cache line 的大小是 64B， 那么就一共有 2K/64B=32 个 Cache line，那么对应我们的内存，第 1 块(地址 0 ~ 63)，第 33 块(地址 64*32 ~ 64*33-1)，以及第(N*32+1)块(地址 64*(N-1)~ 64*N-1)都被映射到 Cache 第一块中;同理，第 2 块，第 34 块，以及第(N*32+2)块都被映射到 Cache 第二块中;可以依次类推其他内存块。

直接关联型 Cache 的目录表只有两部分组成:区号和有效位。首先，内存地址被分成三部分:区号 A、块号 B 和块内地址 C。根据区号 A 在目录表中找到完全相等的区号，并且在有效位有效的情况下，说明该数据在 Cache 中，然后通过内存地址的块号 B 获得在 Cache 中的块地址，加上块内地址 C，最终找到数据。如果在目录表中 找不到相等的区号，或者有效位无效的情况下，则说明该内容不在 Cache 中，需要到内存中 读取。

可以看出，直接关联是一种很“死”的映射方法，当映射到同一个 Cache 块的多个内存块同时需要缓存在 Cache 中时，只有一个内存块能够缓存，其他块需要被“淘汰”掉。因此，直接关联型命中率是最低的，但是其实现方式最为简单，匹配速度也最快。

#### 组关联型Cache

组关联型 Cache 是目前 Cache 中用的比较广泛的一种方式，是前两种 Cache 的折中形 式。在这种方式下，内存被分为很多组，一个组的大小为多个 Cache line 的大小，一个组映 射到对应的多个连续的 Cache line，也就是一个 Cache 组，并且该组内的任意一块可以映射 到对应 Cache 组的任意一个。可以看出，在组外，其采用直接关联型 Cache 的映射方式，而 在组内，则采用全关联型 Cache 的映射方式。

假设有一个 4 路组关联型 Cache，其大小为 1M，一个 Cache line 的大小为 64B，那么 总共有 16K 个 Cache line，但是在 4 路组关联的情况下，我们并不是简简单单拥有 16K 个 Cache line，而是拥有了 4K 个组，每个组有 4 个 Cache line。一个内存单元可以缓存到它所 对应的组中的任意一个 Cache line 中去。

以 4 路组关联型 Cache 为例介绍其在 Cache 中的查找过程。目录表由三部分组成，分别是“区号 + 块号”、Cache 块号和有效位。当收到一个内存地址时，该地址被分成四部分:区号 A、组号 B、块号 C 和块内地址 D。首先，根据组号 B 按地址查找到一组目录表项，在 4 路组关联中，则有四个表项，每个表项都有可能存放该内存块;然后，根据区号 A 和块号 C 在该组表项中进行关联查找(即并行查找，为了提高效率)，如果匹配且有效位有 效，则表明该数据块缓存在 Cache 中，得到 Cache 块号，加上块内地址 D，可以得到该内存地址在 Cache 中映射的地址，得到数据;如果没有找到匹配项或者有效位无效，则表示该内存块不在 Cache 中，需要处理器到内存中读取。



实际上，直接关联型 Cache 和全关联型 Cache 只是组关联型 Cache 的特殊情况，当组内 Cache Line 数目为 1 时，即为直接关联型 Cache。而当组内 Cache Line 数目和 Cache 大小相 等时，即整个 Cache 只有一个组，这成为全关联型 Cache。

### Cache写策略

内存的数据被加载到 Cache 后，在某个时刻其要被写回内存，对于这个时刻的选取，有如下几个不同的策略。

直写(write-through):所谓直写，就是指在处理器对 Cache 写入的同时，将数据写入到 内存中。这种策略保证了在任何时刻，内存的数据和 Cache 中的数据都是同步的，这种方式 简单、可靠。但由于处理器每次对 Cache 更新时都要对内存进行写操作，因此总线工作繁 忙，内存的带宽被大大占用，因此运行速度会受到影响。假设一段程序在频繁地修改一个局 部变量，尽管这个局部变量的生命周期很短，而且其他进程 / 线程也用不到它，CPU 依然会 频繁地在 Cache 和内存之间交换数据，造成不必要的带宽损失。

回写(write-back):回写相对于直写而言是一种高效的方法。直写不仅浪费时间，而且 有时是不必要的，比如上文提到的局部变量的例子。回写系统通过将 Cache line 的标志位 字段添加一个 Dirty 标志位，当处理器在改写了某个 Cache line 后，并不是马上把其写回内 存，而是将该 Cache line 的 Dirty 标志设置为 1。当处理器再次修改该 Cache line 并且写回到 Cache 中，查表发现该 Dirty 位已经为 1，则先将 Cache line 内容写回到内存中相应的位置， 再将新数据写到 Cache 中。其实，回写策略在多核系统中会引起 Cache 一致性的问题。设想 有两个处理器核心都需要对某个内存块进行读写，其中一个核心已经修改了该数据块，并且 写回到 Cache 中，设置了 Dirty 位;这时另外一个核心也完成了该内存块的修改，并且准备写入到 Cache 中，这时才发现该 Cache line 是“脏”的，在这种情况下，Cache 如何处理呢? 之后的章节我们会继续这个话题。

除了上述这两种写策略，还有 WC(write-combining)和 UC(uncacheable)。这两种策略 都是针对特殊的地址空间来使用的。

write-combining 策略是针对于具体设备内存(如显卡的 RAM)的一种优化处理策略。对 于这些设备来说，数据从 Cache 到内存转移的开销比直接访问相应的内存的开销还要高得 多，所以应该尽量避免过多的数据转移。试想，如果一个 Cache line 里的字被改写了，处理 器将其写回内存，紧接着又一个字被改写了，处理器又将该 Cache line 写回内存，这样就显 得低效，符合这种情况的一个例子就是显示屏上水平相连的像素点数据。write-combining 策 略的引入就是为了解决这种问题，顾名思义，这种策略就是当一个 Cache line 里的数据一个 字一个字地都被改写完了之后，才将该 Cache line 写回到内存中。

uncacheable 内存是一部分特殊的内存，比如 PCI 设备的 I/O 空间通过 MMIO 方式被映射成内存来访问。这种内存是不能缓存在 Cache 中的，因为设备驱动在修改这种内存时，总是期望这种改变能够尽快通过总线写回到设备内部，从而驱动设备做出相应的动作。如果放在 Cache 中，硬件就无法收到指令。

### **Cache** 预取

