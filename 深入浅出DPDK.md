---
title: 深入浅出DPDK
toc: true
thumbnail: 'https://pic.downk.cc/item/5eda03efc2a9a83be5241038.jpg'
comments: true
tags:
  - DPDK
date: 2020-07-23 09:01:21
urlname:
categories:
---

最近在做T4P4s多目标编译器，崔博要求T4P4s的前端编译要与DPDK结合起来实现数据平面的完全可编程，并且数据带宽达到40Gbs。就看一下DPDK这本书，结合白皮书入入门。

在早期的网络收发数据量不是特别大的时候，比如10Mbs、100Mbs的传输速率，数据报文的处理都是经过通用架构的Linux内核态，一个报文到来产生一次中断请求，cpu去处理网络报文，当传输速率提升到万兆，甚至英特尔推出的40Gbs、100Gbs的传输速率标准时，仅靠cpu5Ghz的时钟频率显然是不够看的，因此将网络数据的处理从内核态转到应用态是一个发展方向。再此之前的解决方案有轮询，指的是一次中断批处理一批网络报文，而不是一个报文中断一次；还有内存共享技术，减少处理的数据从内核复制到用户的消耗。

### 数据包处理能力

吞吐、延迟、丢包率、抖动

对于转发，常以包转发率（每秒包转发率pps）而不是bit/s来衡量转发效率

一般所说的接口带宽，1Gbit/s、10Gbit/s、25Gbit/s、40Gbit/s、100Gbit/s，代表以太接口线路上所能承载的最高传输比特率，其单位是 bit/s(bit per second， 位 / 秒)。实际上，不可能每个比特都传输有效数据。以太网每个帧之间会有帧间距(Inter- Packet Gap，IPG)，默认帧间距大小为 12 字节。每个帧还有 7 个字节的前导(Preamble)，和 1 个字节的帧首定界符(Start Frame Delimiter，SFD)。

## Cache和内存

### 系统架构的演进

经典计算机系统中的内存架构：

[![](https://pic.downk.cc/item/5f19765614195aa594489c4e.jpg)](https://pic.downk.cc/item/5f19765614195aa594489c4e.jpg)

所有的数据交换都需要经过北桥

1. 处理器访问内存
2. 处理器访问外设
3. 外设访问处理器
4. 外设访问内存

因此，北桥的性能成了系统性能的瓶颈，因此推出了一种架构：

![](https://pic.downk.cc/item/5f19783614195aa59449ad36.png)

这里增加了内存的访问带宽，缓解了不同设备对同一内存访问的拥塞问题，但是没有改进单一北桥芯片的瓶颈问题。为了解决这个问题，产生了NUMA(non-uniform memory architecture非一致性内存架构)系统

![](https://pic.downk.cc/item/5f1ae97214195aa594168cb0.png)

这样的系统架构不需要一个复杂的北桥就能将内存带宽增加到以前的四倍，但是该系统也有缺点，访问内存所花费的时间与处理器有关，如果处理器访问本地内存时间很短，如果访问远程内存，则需要跨越一个或者两个cpu。因此访问内存的时间也是不确定的。

### Cache系统简介

Cache有三级，以前一级和二级放在处理器内部，三级放在主板上，主要是因为三级cache太大，集成进处理器需要的晶体管数量太多，现在工艺都到个位数纳米了，可以集成更多的晶体管，三级cache也被集成进处理器了。

- 一级cache

  一般分为数据cache和指令cache，数据cache主要用来存储数据，而指令cache用于存放指令。这种cache处理速度最快，一般只需要3-5个指令周期就可以访问到数据，因此成本高，容量小，一般都只有几十kb。在多核处理器内部，每个核心都拥有属于自己的一级cache。

- 二级cache

  数据和指令都无差别的存放在一起。速度比一级cache要慢，处理器大约需要十几个处理周期才能访问到数据，一般几百kb到几mb，在多核处理器内部每个核都拥有自己的二级cache。

- 三级cache

  多核处理器共用一个cache。导致一个问题，有可能一个内核占用了大部分的三级cache，而其他内核用极小一部分cache，从而导致cache不命中，性能下降

#### TLB cache

 当程序员直接访问物理地址进行编程时，当程序出现错误，整个系统都崩掉了；或者一个应用程序调用另一个应用程序的写操作，会让另一个应用程序崩掉。因此提出了虚拟内存和分段分页技术。

软件使用虚拟地址访问内存，而处理器负责虚拟地址到物理地址的映射工作，为了完成映射，处理器采取多级页表来进行多次查找找到真正的物理地址。如果查找不到就会产生缺页异常，不会影响到其他的应用程序。

页表存储在内存中，当需要根据虚拟地址查找物理地址时，就要到内存中寻找页目录表和页存表。如果采用TLB Cache的话，集成到处理器内部，就可以大大缩减访问内存的时间，TLB Cache缓存内存中的页表项，采用相连存储器，直接搜索虚拟地址，返回物理地址。如果TLB不命中，则要去内存中查找。

### Cache地址映射和变换

Cache一般只有20-30MB，内存都是以GB为单位的，怎么把内存放到缓存里面呢。这就需要一个映射算法和分块机制。

- 分块机制：是指Cache和内存都是以块进行数据交换，块的大小通常都是以内存一个存储周期中能够访问的数据长度为限。主流块的大小时64字节Bytes，因此一个Cache line就是64字节大小的字节块。
- 映射算法：是指把内存地址空间和Cache地址空间映射起来，把内存中的内容按照某种规则放到Cache中，当处理器需要某个数据块的内容，则可以根据映射规则去Cache中获取

#### 全关联性Cache

全关联型 Cache 是指主存中的任何一块内存都可以映射到 Cache 中的任意一块位置上。在 Cache 中，需要建立一个目录表，目录表的每个表项都有三部分组成:内存地址、Cache 块号和一个有效位。当处理器需要访问某个内存地址时，首先通过该目录表查询是否该内容缓存在 Cache 中。

首先，用内存的块地址 A 在 Cache 的目录表中进行查询，如果找到等值的内存块地址， 检查有效位是否有效，只有有效的情况下，才能通过 Cache 块号在 Cache 中找到缓存的内 存，并且加上块内地址 B，找到相应数据，这时则称为 Cache 命中，处理器拿到数据返回; 否则称为不命中，处理器则需要在内存中读取相应的数据。

可以看出，使用全关联型 Cache，块的冲突最小(没有冲突)，Cache 的利用率也高，但是需要一个访问速度很快的相联存储器。随着 Cache 容量的增加，其电路设计变得十分复杂，因此只有容量很小的 Cache 才会设计成全关联型的(如一些英特尔处理器中的 TLB Cache)。

#### 直接关联型Cache

直接关联型 Cache 是指主存中的一块内存只能映射到 Cache 的一个特定的块中。假设 一个 Cache 中总共存在 N 个 Cache line，那么内存被分成 N 等分，其中每一等分对应一个 Cache line。举个简单的例子，假设 Cache 的大小是 2K，而一个 Cache line 的大小是 64B， 那么就一共有 2K/64B=32 个 Cache line，那么对应我们的内存，第 1 块(地址 0 ~ 63)，第 33 块(地址 64*32 ~ 64*33-1)，以及第(N*32+1)块(地址 64*(N-1)~ 64*N-1)都被映 射到 Cache 第一块中;同理，第 2 块，第 34 块，以及第(N*32+2)块都被映射到 Cache 第 二块中;可以依次类推其他内存块。

直接关联型 Cache 的目录表只有两部分组成:区号和有效位。首先，内存地址被分成三部分:区号 A、块号 B 和块内地址 C。根据区号 A 在目录表中 找到完全相等的区号，并且在有效位有效的情况下，说明该数据在 Cache 中，然后通过内存地址的块号 B 获得在 Cache 中的块地址，加上块内地址 C，最终找到数据。如果在目录表中 找不到相等的区号，或者有效位无效的情况下，则说明该内容不在 Cache 中，需要到内存中 读取。

可以看出，直接关联是一种很“死”的映射方法，当映射到同一个 Cache 块的多个内存块同时需要缓存在 Cache 中时，只有一个内存块能够缓存，其他块需要被“淘汰”掉。因此，直接关联型命中率是最低的，但是其实现方式最为简单，匹配速度也最快。

#### 组关联型Cache

组关联型 Cache 是目前 Cache 中用的比较广泛的一种方式，是前两种 Cache 的折中形 式。在这种方式下，内存被分为很多组，一个组的大小为多个 Cache line 的大小，一个组映 射到对应的多个连续的 Cache line，也就是一个 Cache 组，并且该组内的任意一块可以映射 到对应 Cache 组的任意一个。可以看出，在组外，其采用直接关联型 Cache 的映射方式，而 在组内，则采用全关联型 Cache 的映射方式。

假设有一个 4 路组关联型 Cache，其大小为 1M，一个 Cache line 的大小为 64B，那么 总共有 16K 个 Cache line，但是在 4 路组关联的情况下，我们并不是简简单单拥有 16K 个 Cache line，而是拥有了 4K 个组，每个组有 4 个 Cache line。一个内存单元可以缓存到它所 对应的组中的任意一个 Cache line 中去。